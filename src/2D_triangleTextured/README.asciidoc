== Textured Triangles
:toc:
:!numbered:

=== Summary

Here we introduce texturing of our triangles. Texturing main purpose is to add visual detail to a scene, without the addition of more geometry. This example builds on 2D_trianglesWithGLM, and behaves the same - two triangles, in different positions, each changing differently over time - but each triangle is colored in with texture details. The example, also introduces using the Alpha channel in the fragment shader, to Discard fragments that we don't wish to display.

Texture data is classically stored as images (in our file system). These can be in a variety of formats, both familiar formats such as `.bmp` and `.png`, as well as formats specific to computer graphics such as `.dds` (DirectDraw Surface ). To use the image data in OpenGL we need to load and decompress those files, into a simple flat array of color data. We'll need to use an image loading library for this. SDL2 can load `.bmp` without additional libraries (at least, 24-bit `.bmp` files), but we want to be able to load from other file formats. Specifically, `.png` and `.jpg` format files - see http://www.labnol.org/software/tutorials/jpeg-vs-png-image-quality-or-bandwidth/5385/[labnol.org] for a quick comparison.

There are a large variety of image loading libraries, including https://www.libsdl.org/projects/SDL_image/[SDL_image], which we'll use in this example, and the  https://github.com/nothings/stb/blob/master/stb_image.h[header-only image library stb_image.h from nothings]. There are many, many others.

==== Premake

To use SDL_image we'll need to alter our premake file so that we our build system can find the appropriate files. On Windows, SDL_image is in the `graphics_dependencies` submodule. On Linux, you should make sure the SDL_image development library is installed (`libsdl2-image-dev` on Debian/Ubuntu).

.Add the path to SDL2_image headers on Windows. On Linux the headers should be in a standard location.
[source, lua]
----
include::../../premake5.lua[tags=headers]
----

.Add SDL2_image to the list of required libraries
[source, lua]
----
include::../../premake5.lua[tags=libraries]
----

.Add the path to pre-built libraries on Windows. Libraries should be in a standard location on Linux.
[source, lua]
----
include::../../premake5.lua[tags=librariesDirs]
----

.On Windows, make premake copy the needed `.dll` files to the project location.
[source, lua]
----
include::../../premake5.lua[tags=windowsDLLCopy]
----

==== Vertex Shader

We are only going to use our texture information to change the color of fragments, but we still have to make a few changes in the vertex shader.

In order for texturing to work we need to provide, for each vertex, a position in the texture where the color information is sampled from. This means for each vertex we have yet more information in attributes. These texture coordinates (usually 2D, typically referred to as UV coordinates) per-vertex are then passed onto the fragment shader (interpolated by the rasterizer).

In our Vertex Shader we need to add an `in vec2` attribute for the `vertexUV`, and an `out vec2` to pass on to the fragment shader (`fragmentUV`). Finally, we need to just pass on `vertexUV` to `fragmentUV`.

[source, glsl]
----
include::vertexShader.glsl[]
----

==== Fragment Shader

Our Fragment Shader will need to lookup (sample) color from the texture. To do this it needs to use a sampling unit. The sampling unit it will use will be setup from pass:[C++] to know which texture from sample from. We can have multiple texture samplers, so we'll have a uniform sampler variable that we can set from our pass:[C++], so we can choose between them.

To do the actual sampling, we just call `texture` in our shader, with a sampler and some coordinates, which will return a vec4 of information from the texture.

The image we'll use for this example, has an alpha channel, representing transparency. We'll use this in fragment shader to Discard fragments with a low alpha value.

NOTE: Texturing can be difficult to debug. This Fragment Shader has a line commented out that can help - where we use the UV coordinates directly as colors, which will show if the UV coordinates are working correctly.

[source, glsl]
----
include::fragmentShader.glsl[]
----

===== Include SDL_image in our pass:[C++]

We just need to include `SDL_image.h` in our pass:[C++].

[source, cpp]
----
include::main.cpp[tags=includes]
----

===== `vertexData`

We need to add UV coordinates to our `vertexData`

[source, cpp]
----
include::main.cpp[tags=vertexData]
----

===== New GL variables

We have a new attribute, a new Uniform, and a ID for a texture. We need to add pass:[C++] variables to store them.

[source, cpp]
----
include::main.cpp[tags=GLVariables]
----

===== Get the Attribute and Uniform locations

We need to ask OpenGL for the locations of our new attributes and uniforms on our GLSL program.

[source, cpp]
----
include::main.cpp[tags=getLocations]
----

===== Setup Vertex Array Object

The structure of `vertexData` has changed, we need to update the Vertex Array Object to match that structure, and enable the VertexAttribArray for the location of `vertexUV`.

[source, cpp]
----
include::main.cpp[tags=initializeVertexArrayObject]
----

===== initialize Texture and Sampler

We need to load an image file, create a texture in OpenGL, and load the image data to it. We also need to setup parameters around how that texture should be sampled.

SDL_image loads an image into an SDL_surface, which gives us the pixel data as well as other properties of the image. We can then generate a texture, bind it and load the pixel data from the SDL_surface.

Then we can have OpenGL generate MipMaps of our texture (pre-computed lower resolution versions of the texture), and set up how values should be calculated from the texture when it is being scaled up or down (magnification and minification).

Finally, we unbind the texture to be safe, and free up the pass:[C++] memory used by the image.

NOTE: we've hard coded both the format that the data is in and how it's stored in OpenGL. The latter is up to us, the former should be based on the image we've loaded. In this case, we know the data is in RGBA format, but it could be others.

[source, cpp]
----
include::main.cpp[tags=initializeTexturesAndSamplers]
----

===== Set texture and sampler unit in render

When rendering, we need to let OpenGL know which sampler to feed from which texture unit - in our case, feed the location that `textureSampler` is in from texture unit 0. We need to then bind a texture to that texture unit - by making that unit the active one, then binding the texture ID to it (the currently active one).

[source, cpp]
----
include::main.cpp[tags=render]
----


NOTE: We are no longer using the colour information from `vertexData`, and the GLSL compilers are clever, so when we try to get the locations of the associated attributes and uniforms, we now get values of -1 returned (which are invalid). We could remove these parts, and using those -1 values in `glEnableVertexAttribArray` and `glVertexAttribPointer` does generate glErrors (if we check for them), but for now we'll just let them stay - OpenGL just ignores the errors.
